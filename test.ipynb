{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import MRIDataset\n",
    "# from residual3dunet.model import ResidualUNet3D\n",
    "from residual3dunet.res3dunetmodel import ResidualUNet3D\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import compute_average, add_mask_colour, greytoRGB, plot_overlapped, preprocess, read_data_as_numpy, write_to_h5, read_data_from_h5\n",
    "import torchvision.transforms as T\n",
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_to_h5('./dataset/test/T2', 'T2test')\n",
    "\n",
    "\n",
    "\n",
    "# x = read_data_from_h5('./dataset/T2train.h5', 2)\n",
    "# y = read_data_from_h5('./dataset/T2trainmask.h5', 2)\n",
    "# print(x.shape)\n",
    "\n",
    "# print(torch.amax(x))\n",
    "\n",
    "\n",
    "# for i in range(14):\n",
    "#     fig = plt.figure()\n",
    "#     plt.imshow(x[0,i,:,:], cmap='gray')\n",
    "#     plt.imshow(y[0,i,:,:], cmap='gray',alpha=0.3)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotloss('output/train16.out')\n",
    "plt.figure()\n",
    "# plotaccuracy('output/train6.out')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model = ResidualUNet3D(in_channels=1, out_channels=1, testing=True).to(device)\n",
    "\n",
    "# model = torch.nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(\"model28.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdataset = MRIDataset(train=True, transform=T.Compose([T.ToTensor()]))\n",
    "# test_loader = DataLoader(dataset = testdataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# print(len(test_loader))\n",
    "\n",
    "\n",
    "for i in range(1,50):\n",
    "    image_path = f'./dataset/test/T2/MRI{i}_T2.nii.gz'\n",
    "    image_data = preprocess(read_data_as_numpy(image_path))\n",
    "\n",
    "    # image_data = preprocess(image_data)\n",
    "    print(image_data.shape)\n",
    "    # print(torch.amax(image_data))\n",
    "\n",
    "\n",
    "# # Plot 3D data depth-wise\n",
    "# for i in range(14):\n",
    "#     fig = plt.figure()\n",
    "#     plt.imshow(image_data[i,:,:], cmap='gray')\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "# for data, target in test_loader:\n",
    "#     print(data.shape)\n",
    "    # print(target.shape)\n",
    "\n",
    "# dataiter = iter(test_loader)\n",
    "# data = dataiter.next()\n",
    "# # data = dataiter.next()\n",
    "# # data = dataiter.next()\n",
    "# features, labels = data\n",
    "\n",
    "# features, labels = features.float().to(device), labels.float().to(device)\n",
    "\n",
    "# # image_data = image_data.float().to(device)\n",
    "# print(torch.amax(features))\n",
    "# # print(features)\n",
    "# # output = model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(14):\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(x[0,i,:,:], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = torch.sigmoid(output)\n",
    "preds = (output > 0.5).float()\n",
    "\n",
    "# print(preds.shape)\n",
    "# print(labels.shape)\n",
    "batch, channel, depth, width, height = preds.shape\n",
    "\n",
    "\n",
    "print(features.shape)\n",
    "print(preds.shape)\n",
    "print(labels.shape)\n",
    "# print(dice_coefficient(preds, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import to_depth_last, convert_to_numpy\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def plot_overlapped(feature, prediction, target, size=(3,3)):\n",
    "    \"\"\"Plot the feature, predicted mask and groundtruth overlapping each other.\n",
    "    Args:\n",
    "        feature (np.ndarray/torch.tensors): A 3D or a 4D array/tensor, the original feature image\n",
    "        prediction (np.ndarray/torch.tensors): A 3D or a 4D array/tensor, the predicted mask\n",
    "        target (np.ndarray/torch.tensors): A 3D or a 4D array/tensor, the ground truth mask\n",
    "    \"\"\"\n",
    "    # Plotting the data, prediction and target, overlapping each other\n",
    "\n",
    "    assert len(feature.shape) in (3,4), 'feature must contain 3 or 4 dimensions: (W*H*D) or (C*W*H*D)'\n",
    "    assert len(prediction.shape) in (3,4), 'prediction must contain 3 or 4 dimensions: (W*H*D) or (C*W*H*D)'\n",
    "    assert len(target.shape) in (3,4), 'target must contain 3 or 4 dimensions: (W*H*D) or (C*W*H*D)'\n",
    "\n",
    "    # Preprocessing feature, prediction and target\n",
    "    # feature = convert_to_numpy(to_depth_last(feature))\n",
    "    feature = convert_to_numpy(to_depth_last(feature))\n",
    "    prediction = convert_to_numpy(to_depth_last(prediction))\n",
    "    target = convert_to_numpy(to_depth_last(target))\n",
    "\n",
    "    depth = prediction.shape[-1]\n",
    "\n",
    "    # Convert to 3D\n",
    "    feature = np.squeeze(feature)\n",
    "    prediction = np.squeeze(prediction)\n",
    "    target = np.squeeze(target)\n",
    "\n",
    "    prediction = add_mask_colour(prediction, \"red\")\n",
    "    target = add_mask_colour(target, \"blue\")\n",
    "\n",
    "    overlap = prediction + target\n",
    "\n",
    "    # feature[overlap.astype(bool)] = 1\n",
    "\n",
    "    # Colour labelling\n",
    "    colors = [(1,0,0,1), (0,0,1,1), (1,0,1,1)]\n",
    "    values = ['prediction', 'target', 'overlapped']\n",
    "    patches = [ mpatches.Patch(color=colors[i], label=values[i] ) for i in range(len(values)) ]\n",
    "\n",
    "    # Save image to pdf\n",
    "    pdf = PdfPages(\"result1.pdf\")\n",
    "\n",
    "    # Plot 3D data depth-wise\n",
    "    for i in range(depth):\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(feature[:,:,i], cmap='gray')\n",
    "        plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0. )\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        pdf.savefig(fig)\n",
    "\n",
    "    pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = plot_overlapped(features[0,:,:,:,:], preds[0,:,:,:,:], labels[0,:,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Colour labelling\n",
    "colors = [(1,0,0,1), (0,0,1,1), (1,0,1,1)]\n",
    "values = ['prediction', 'target', 'overlapped']\n",
    "patches = [ mpatches.Patch(color=colors[i], label=values[i] ) for i in range(len(values)) ]\n",
    "\n",
    "def explore_3d_image(layer):\n",
    "    \n",
    "    plt.figure(figsize=(5,10))\n",
    "    plt.imshow(out[:,:,layer,:],cmap='gray')\n",
    "    plt.title('Explore Segmented MRI')\n",
    "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0. )\n",
    "    plt.axis('off')\n",
    "    return layer\n",
    "\n",
    "interact(explore_3d_image, layer=(0,out.shape[2]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Single Image Data\n",
    "f, axarr = plt.subplots(14,3,figsize=(50,50))\n",
    "\n",
    "for i in range(depth):\n",
    "    axarr[i,0].imshow(features[0,0,i,:,:],cmap='gray')\n",
    "    axarr[i,1].imshow(preds[0,0,i,:,:],cmap='gray')\n",
    "    axarr[i,2].imshow(labels[0,0,i,:,:],cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_statistics import SegmentationStatistics\n",
    "\n",
    "preds = preds.numpy()\n",
    "labels = labels.numpy()\n",
    "prediction = preds.astype(bool)\n",
    "gt = labels.astype(bool)\n",
    "\n",
    "# preds = preds.bool()\n",
    "# labels = labels.bool()\n",
    "\n",
    "stat = SegmentationStatistics(prediction[0,0,:,:,:], gt[0,0,:,:,:], (3,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.print_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = add_mask_colour(labels, \"blue\")\n",
    "preds = add_mask_colour(preds, \"red\")\n",
    "overlap = labels + preds\n",
    "\n",
    "features =torch.squeeze(features, 0)\n",
    "overlapped = overlap.astype(bool)\n",
    "testfeatures = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     plt.imshow(features[0,0,layer,:,:],cmap='gray')\n",
    "#     plt.imshow(overlap[layer,:,:,:], alpha=0.8)\n",
    "#     plt.title('Explore Segmented MRI')\n",
    "#     plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0. )\n",
    "#     plt.axis('off')\n",
    "#     # return layer\n",
    "\n",
    "# interact(explore_3d_image,layer=(0,features.shape[2]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(depth):\n",
    "    plt.imshow(overlap[i,:,:,:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7aa30a5429a76fc9327cf5c7d6cbac98b63911354387ecfa6ca386d1236b51ba"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
